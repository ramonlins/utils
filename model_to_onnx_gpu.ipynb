{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c113a3a1",
   "metadata": {},
   "source": [
    "# Accelerating and scaling inference with ONNX on GPU\n",
    "## 01 - Getting started\n",
    "#### By Ramon Lins\n",
    "------------------\n",
    "\n",
    "**Table of contents**\n",
    "* [Introduction](#introduction)\n",
    "* [Setup](#setup)\n",
    "* [Tutorial](#tutorial)\n",
    "* [Visualization](#zetane)\n",
    "* [Optional](#option)\n",
    "\n",
    "Reference:\n",
    "\n",
    "- Tutorial\n",
    "    > https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html(cpu tutorial)\n",
    "    \n",
    "    > https://pytorch.org/docs/master/onnx.html\n",
    "\n",
    "- Setup\n",
    "    > https://onnxruntime.ai/\n",
    "\n",
    "    > https://developer.nvidia.com/cuda-10.1-download-archive-update2?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1804&target_type=deblocal (cuda 10.1)\n",
    "\n",
    "    > https://developer.nvidia.com/compute/machine-learning/cudnn/secure/7.6.5.32/Production/10.2_20191118/cudnn-10.2-linux-x64-v7.6.5.32.tgz (cudnn 7.6.5)\n",
    "\n",
    "    > https://docs.nvidia.com/cuda/cuda-installation-guide-linux/\n",
    "\n",
    "- ONNX\n",
    "    > https://onnxruntime.ai/docs/tutorials/export-pytorch-model.html\n",
    "    \n",
    "    > https://pytorch.org/docs/master/onnx.html\n",
    "\n",
    "- ONNXRuntime\n",
    "    > https://onnxruntime.ai/docs/tutorials/\n",
    "    \n",
    "    > https://github.com/microsoft/onnxruntime\n",
    "    \n",
    "    > https://onnxruntime.ai/docs/tutorials/accelerate-pytorch/pytorch.html\n",
    "\n",
    "    > https://github.com/microsoft/onnxruntime/blob/master/onnxruntime/python/tools/transformers/notebooks/PyTorch_Bert-Squad_OnnxRuntime_GPU.ipynb (gpu tutorial)\n",
    "    \n",
    "    > https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html(version compatibility)\n",
    "    \n",
    "    > https://onnxruntime.ai/docs/build/eps.html#cuda\n",
    "    \n",
    "- Visualization\n",
    "    > https://github.com/onnx/tutorials/blob/main/tutorials/VisualizingAModel.md\n",
    "\n",
    "- Comparison\n",
    "    > https://github.com/onnx/tutorials/blob/main/tutorials/CorrectnessVerificationAndPerformanceComparison.ipynb\n",
    "\n",
    "- Optional\n",
    "    > https://github.com/onnx/onnx-docker/blob/master/onnx-ecosystem/converter_scripts/float32_float16_onnx.ipynb\n",
    "    \n",
    "    > https://github.com/onnx/onnx-docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aecf0f",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n",
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8762887f",
   "metadata": {},
   "source": [
    "<a id=\"introduction\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd59257",
   "metadata": {},
   "source": [
    "ONNX is an open source project designed to accelerate machine learning across a wide variety of \n",
    "frameworks, operating systems, and hardware platforms.\n",
    "\n",
    "The main objective of this task is to use the ONNX engine to optimize the patch-based density model,\n",
    "a vgg-16 customized network, to reducing latency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72e6c1c",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12592b88",
   "metadata": {},
   "source": [
    "Create a environment.yml with:\n",
    "```\n",
    "name: onnx_gpu\n",
    "channels:\n",
    "  - pytorch-lts\n",
    "dependencies:\n",
    "  - python=3.7.*\n",
    "  - pytorch=1.8.2\n",
    "  - torchvision=0.9.2\n",
    "  - cudatoolkit=10.2\n",
    "  - pip\n",
    "  - pip:\n",
    "      - onnx\n",
    "      - onnxruntime-gpu==1.4\n",
    "```\n",
    "run in terminal\n",
    "\n",
    "```\n",
    "conda env create\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc18b7cd",
   "metadata": {},
   "source": [
    "Prerequistes to run the jupyter notebook:\n",
    "```bash\n",
    "conda activate onnx_gpu\n",
    "conda install -c anaconda ipykernel\n",
    "conda install -c conda-forge ipywidgets\n",
    "python -m ipykernel install --user --name=onnx_gpu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257940d8",
   "metadata": {},
   "source": [
    "<a id=\"tutorial\"></a>\n",
    "### Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a518b3b",
   "metadata": {},
   "source": [
    "Pytorch use build-in cuda and cudnn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cafc4f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.8.2\n",
      "cuda version: 10.1\n",
      "cudnn version: 7603\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.init as init\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "print(\"pytorch version:\", torch.__version__)\n",
    "print(\"cuda version:\" , torch.version.cuda)\n",
    "print(\"cudnn version:\", torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a81f39",
   "metadata": {},
   "source": [
    "To run onnx runtime, cuda and cudnn version should be installed from source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d286c1a",
   "metadata": {},
   "source": [
    "To install ***cuda*** (10.1) from source follow the instructions:\n",
    "\n",
    "```bash\n",
    "wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
    "\n",
    "sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
    "\n",
    "wget https://developer.download.nvidia.com/compute/cuda/10.1/Prod/local_installers/cuda-repo-ubuntu1804-10-1-local-10.1.243-418.87.00_1.0-1_amd64.deb\n",
    "\n",
    "sudo dpkg -i cuda-repo-ubuntu1804-10-1-local-10.1.243-418.87.00_1.0-1_amd64.deb\n",
    "\n",
    "sudo apt-key add /var/cuda-repo-10-1-local-10.1.243-418.87.00/7fa2af80.pub\n",
    "\n",
    "sudo apt-get update\n",
    "\n",
    "sudo apt-get -y install cuda\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28557a4e",
   "metadata": {},
   "source": [
    "To install ***cudnn*** (7.6.5) from source follow the instructions:\n",
    "\n",
    "```bash\n",
    "wget https://developer.nvidia.com/compute/machine-learning/cudnn/secure/7.6.5.32/Production/10.2_20191118/cudnn-10.2-linux-x64-v7.6.5.32.tgz\n",
    "\n",
    "tar -zxf cudnn-10.2-linux-x64-v7.6.5.32.tgz\n",
    "\n",
    "cd cuda\n",
    "sudo cp -P lib64/* /usr/local/cuda/lib64/\n",
    "sudo cp -P include/* /usr/local/cuda/include/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbd3f74",
   "metadata": {},
   "source": [
    "Perhaps environment paths are not set correctly, so after Install CUDA and cuDNN:\n",
    "- The path to the CUDA installation must be provided via the `CUDA_PATH` environment variable\n",
    "- The path to the cuDNN installation (include the cuda folder in the path) must be provided via the `cuDNN_PATH` environment variable. The cuDNN path should contain bin, include and lib directories.\n",
    "https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html\n",
    "\n",
    "export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}\n",
    "\n",
    "export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "630f0190",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionNet(nn.Module):\n",
    "    def __init__(self, upscale_factor: int):\n",
    "        \"\"\"Super Resolution Network for increasing the resolutiono of images\n",
    "\n",
    "        Args:\n",
    "            upscale_factor (int): The factor by which the image resolution is increased\n",
    "        \"\"\"\n",
    "        super(SuperResolutionNet, self).__init__()\n",
    "        global batch_size \n",
    "        batch_size = 1 # Batch size\n",
    "        num_filters = 64 # number of filters\n",
    "        kernel_size_in = 5 # 5x5 kernel for input convolution\n",
    "        kernel_size_hl = 3 # 3x3 kernel for hidden layer convolution\n",
    "        stride = 1 # stride of the convolution\n",
    "        padding_in = 2 # padding for input convolution\n",
    "        padding_hl = 1 # padding for hidden layers\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(batch_size, num_filters, kernel_size_in, stride, padding_in)\n",
    "        self.conv2 = nn.Conv2d(num_filters, num_filters, kernel_size_hl, stride, padding_hl)\n",
    "        self.conv3 = nn.Conv2d(num_filters, num_filters//2, kernel_size_hl, stride, padding_hl)\n",
    "        self.conv4 = nn.Conv2d(num_filters//2, upscale_factor**2, kernel_size_hl, stride, padding_hl)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"forward operation\n",
    "\n",
    "        Args:\n",
    "            x (tensor): input image of shape (batch_size, 1, H, W)\n",
    "\n",
    "        Returns:\n",
    "            tensor: output image of shape (batch_size, 1, H*upscale_factor, W*upscale_factor)\n",
    "        \"\"\"\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        \n",
    "        return self.pixel_shuffle(self.conv4(x))\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        #initialize weights for the network using orthogonal initialization\n",
    "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv4.weight)\n",
    "\n",
    "\n",
    "model = SuperResolutionNet(upscale_factor=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fbc6d9",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperResolutionNet(\n",
       "  (relu): ReLU()\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pixel_shuffle): PixelShuffle(upscale_factor=3)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained model weights\n",
    "model_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth'\n",
    "\n",
    "# pretrained model weights\n",
    "model.load_state_dict(model_zoo.load_url(model_url))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "\n",
    "# evaluation mode\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd3b74",
   "metadata": {},
   "source": [
    "Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10d1a8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch inference time = 41.80208492279053\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "total_samples = 10000\n",
    "torch_inputs = torch.randn(total_samples, batch_size, 224, 224, requires_grad=True).to(device)\n",
    "\n",
    "latency = []\n",
    "\n",
    "# inference torch\n",
    "for i in range(total_samples):\n",
    "    torch_input = torch_inputs[i].unsqueeze_(0)\n",
    "    start = time.time()\n",
    "    model(torch_input)\n",
    "    latency.append(time.time() - start)\n",
    "\n",
    "print(f\"Pytorch inference time = {sum(latency)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbdff73",
   "metadata": {},
   "source": [
    "Export pytorch to onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9dd2a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx version: 1.12.0\n",
      "onnxruntime version: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "print(\"onnx version:\", onnx.__version__)\n",
    "print(\"onnxruntime version:\", onnxruntime.__version__)\n",
    "\n",
    "onnx_version = onnx.__version__.split('.')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d44f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'SuperResolutionNet' object has no attribute 'graph'\n"
     ]
    }
   ],
   "source": [
    "# input example necessary to export onnx model\n",
    "torch_input = torch.randn(1, 1, 224, 224, requires_grad=True).to(device)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model, # model being run\n",
    "    torch_input, # model input (or a tuple for multiple inputs)\n",
    "    \"superres.onnx\", # where to save the model (can be a file or file-like object)\n",
    "    export_params=True, # store the trained parameter weights inside the model file\n",
    "    input_names=['input'], # the model's input names\n",
    "    output_names=['output'], # the model's output names\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}) # variable length axes\n",
    "\n",
    "try:\n",
    "    # print human readable representation of the graph if exist\n",
    "    print(onnx.helper.printable_graph(model.graph))\n",
    "except AttributeError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e350a1e",
   "metadata": {},
   "source": [
    "Before verifying the model’s output with ONNX Runtime, we will check the ONNX model with ONNX’s API. \n",
    "\n",
    "1. First, onnx.load(\"superres.onnx\") will load the saved model and will output a onnx.ModelProto structure (a top-level file/container format for bundling a ML model. For more information onnx.proto documentation.). \n",
    "2. Then, onnx.checker.check_model(onnx_model) will verify the model’s structure and confirm that the model has a valid schema. The validity of the ONNX graph is verified by checking the model’s version, the graph’s structure, as well as the nodes and their inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba4cba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX export is valid.\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(\"superres.onnx\")\n",
    "# check consistency of the model. \n",
    "# if model is larger than 2GB, should model should be checked with path instead of model itself\n",
    "print(\"ONNX export is valid.\") if onnx.checker.check_model(onnx_model) == None else print(\"ONNX export is invalid.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e7510",
   "metadata": {},
   "source": [
    "Compute inference output using onnx runtime.\n",
    "\n",
    "To run the model, it is necessary to create an inference session. Once it is created, the model is evaluated using `run()` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33ae2b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX and PyTorch results match!\n"
     ]
    }
   ],
   "source": [
    "#  explicity execution Providers (EP) framework\n",
    "# BUG: An warning is issued when the EP is used.\n",
    "provider = ['CPUExecutionProvider'] if device.type == \"cpu\" else ['CUDAExecutionProvider']\n",
    "\n",
    "# create a onnx runtime session\n",
    "session = onnxruntime.InferenceSession(\"superres.onnx\", providers=provider)\n",
    "\n",
    "# NOTE: This can be a bottleneck for gpu devices, since the tensor is transferred to cpu to\n",
    "# convert to numpy array. Then, the numpy array is transferred to gpu .\n",
    "\n",
    "# turn tensor into numpy array \n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# inference onnx\n",
    "onnx_output = session.run(None, {\"input\": to_numpy(torch_input)},)\n",
    "\n",
    "# inference pytorch\n",
    "torch_output = model(torch_input)\n",
    "\n",
    "# compare onnx X with pytorch results\n",
    "try:\n",
    "    np.testing.assert_allclose(to_numpy(torch_output), onnx_output[0], rtol=1e-03, atol=1e-05)\n",
    "    print(\"ONNX and PyTorch results match!\")\n",
    "except AssertionError as error:\n",
    "    print(\"ONNX and PyTorch results do not match!\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16403c87",
   "metadata": {},
   "source": [
    "Test latency inference output with ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee6f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_inputs = []\n",
    "for i in range(total_samples):\n",
    "    onnx_inputs.append(to_numpy(torch_inputs[i].unsqueeze_(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1b0e04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX inference time = 49.88228797912598\n"
     ]
    }
   ],
   "source": [
    "latency = []\n",
    "for onnx_input in onnx_inputs:\n",
    "    onnx_input = {\"input\": onnx_input}\n",
    "    start = time.time()\n",
    "    onnx_output = session.run(None, onnx_input)\n",
    "    latency.append(time.time() - start)\n",
    "\n",
    "print(f\"ONNX inference time = {sum(latency)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31d7d48",
   "metadata": {},
   "source": [
    "Test using images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bcd6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "img = Image.open(\"/home/ramon/Git/utils/img/cat.jpg\")\n",
    "\n",
    "resize= transforms.Resize([224, 224])\n",
    "img_rs = resize(img)\n",
    "\n",
    "img_ycbcr = img_rs.convert('YCbCr')\n",
    "img_y, img_cb, img_cr = img_ycbcr.split()\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_y = to_tensor(img_y)\n",
    "img_y = img_y.unsqueeze_(0)\n",
    "\n",
    "# inference\n",
    "onnx_inputs = {session.get_inputs()[0].name: to_numpy(img_y)}\n",
    "onnx_output = session.run(None, onnx_inputs)\n",
    "img_out_y = onnx_output[0]\n",
    "\n",
    "img_out_y = Image.fromarray(np.uint8((img_out_y[0] * 255.0).clip(0, 255)[0]), mode='L')\n",
    "\n",
    "# get the output image follow post-processing step from PyTorch implementation\n",
    "final_img = Image.merge(\n",
    "    \"YCbCr\", [\n",
    "        img_out_y,\n",
    "        img_cb.resize(img_out_y.size, Image.BICUBIC),\n",
    "        img_cr.resize(img_out_y.size, Image.BICUBIC),\n",
    "    ]).convert(\"RGB\")\n",
    "\n",
    "# Save the image, we will compare this with the output image from mobile device\n",
    "final_img.save(\"./out/cat.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('utils')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1e890fa95ed0ec9c8fb286e04549f6077243facc59f1dcdc56b3adff9cce08d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
